{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d92262",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:16.696305Z",
          "iopub.status.busy": "2021-12-11T18:03:16.695433Z",
          "iopub.status.idle": "2021-12-11T18:03:19.296455Z",
          "shell.execute_reply": "2021-12-11T18:03:19.295846Z",
          "shell.execute_reply.started": "2021-12-10T10:25:19.623876Z"
        },
        "papermill": {
          "duration": 2.659793,
          "end_time": "2021-12-11T18:03:19.296616",
          "exception": false,
          "start_time": "2021-12-11T18:03:16.636823",
          "status": "completed"
        },
        "tags": [],
        "id": "b5d92262"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "from skimage import io\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models import resnet50, vgg19\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, MaskRCNN, FasterRCNN, retinanet_resnet50_fpn\n",
        "from torchvision.models.detection.rpn import AnchorGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd9eec5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:19.335473Z",
          "iopub.status.busy": "2021-12-11T18:03:19.334931Z",
          "iopub.status.idle": "2021-12-11T18:03:19.444613Z",
          "shell.execute_reply": "2021-12-11T18:03:19.444081Z",
          "shell.execute_reply.started": "2021-12-10T10:25:26.939328Z"
        },
        "papermill": {
          "duration": 0.131239,
          "end_time": "2021-12-11T18:03:19.444745",
          "exception": false,
          "start_time": "2021-12-11T18:03:19.313506",
          "status": "completed"
        },
        "tags": [],
        "id": "cbd9eec5"
      },
      "outputs": [],
      "source": [
        "train_path = '../input/tensorflow-great-barrier-reef/train_images/'\n",
        "df_path = '../input/tensorflow-great-barrier-reef/train.csv'\n",
        "df = pd.read_csv(df_path).iloc[:, [0, 2, -1]]\n",
        "test_df = pd.read_csv('../input/tensorflow-great-barrier-reef/test.csv').iloc[:, [0, 2]]\n",
        "star_df = df[df['annotations'] != '[]']\n",
        "non_df = df[df['annotations'] == '[]']\n",
        "batch_size = 4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first we pretrain the backbone for 5 epochs for classification to get better feature maps for detection."
      ],
      "metadata": {
        "id": "n8r3jaCfU6LG"
      },
      "id": "n8r3jaCfU6LG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e6d11e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:19.491687Z",
          "iopub.status.busy": "2021-12-11T18:03:19.490712Z",
          "iopub.status.idle": "2021-12-11T18:03:19.492463Z",
          "shell.execute_reply": "2021-12-11T18:03:19.493016Z",
          "shell.execute_reply.started": "2021-12-10T10:25:28.76436Z"
        },
        "papermill": {
          "duration": 0.032143,
          "end_time": "2021-12-11T18:03:19.493173",
          "exception": false,
          "start_time": "2021-12-11T18:03:19.461030",
          "status": "completed"
        },
        "tags": [],
        "id": "f7e6d11e"
      },
      "outputs": [],
      "source": [
        "class ClassiData(Dataset):\n",
        "    def __init__(self, train_path, star_df, non_df):\n",
        "        self.star = star_df\n",
        "        self.star = np.concatenate((self.star, np.ones((len(self.star),1))), axis = 1)\n",
        "        self.non = non_df\n",
        "        self.non = np.concatenate((self.non, np.zeros((len(self.non),1))), axis = 1)\n",
        "        self.random_choice()\n",
        "        self.path = train_path\n",
        "        self.transforms = T.Compose([T.ToPILImage(), T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "    def random_choice(self):\n",
        "        rand = np.random.choice(len(self.non), len(self.star), replace = False)\n",
        "        df = np.concatenate((self.star, self.non[rand]), axis = 0)\n",
        "        np.random.shuffle(df)\n",
        "        self.ids = df[:, 0]\n",
        "        self.frames = df[:, 1]\n",
        "        self.labels = df[:, -1]\n",
        "    def __len__(self):\n",
        "        return 2 * len(self.star)\n",
        "    def __getitem__(self, idx):\n",
        "        im_path = f'{self.path}video_{self.ids[idx]}/{self.frames[idx]}.jpg'\n",
        "        label = self.labels[idx]\n",
        "        image = io.imread(im_path)\n",
        "        image = torch.from_numpy(image)\n",
        "        image = image.permute((2, 0, 1))\n",
        "        image = self.transforms(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = image.flip(-1)\n",
        "        if idx == len(self):\n",
        "            self.random_choice()\n",
        "        return image, torch.tensor([label]).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cf3837",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:19.530696Z",
          "iopub.status.busy": "2021-12-11T18:03:19.529988Z",
          "iopub.status.idle": "2021-12-11T18:03:19.532632Z",
          "shell.execute_reply": "2021-12-11T18:03:19.532189Z",
          "shell.execute_reply.started": "2021-12-09T12:01:44.642444Z"
        },
        "papermill": {
          "duration": 0.022673,
          "end_time": "2021-12-11T18:03:19.532751",
          "exception": false,
          "start_time": "2021-12-11T18:03:19.510078",
          "status": "completed"
        },
        "tags": [],
        "id": "a0cf3837"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33502d88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:19.570766Z",
          "iopub.status.busy": "2021-12-11T18:03:19.570084Z",
          "iopub.status.idle": "2021-12-11T18:03:22.342793Z",
          "shell.execute_reply": "2021-12-11T18:03:22.342262Z",
          "shell.execute_reply.started": "2021-12-10T10:25:31.149025Z"
        },
        "papermill": {
          "duration": 2.794197,
          "end_time": "2021-12-11T18:03:22.342930",
          "exception": false,
          "start_time": "2021-12-11T18:03:19.548733",
          "status": "completed"
        },
        "tags": [],
        "id": "33502d88"
      },
      "outputs": [],
      "source": [
        "resnet = torch.load('../input/resnet50/resnet50.pth')\n",
        "backbone = resnet50()\n",
        "backbone.load_state_dict(resnet)\n",
        "backbone.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "backbone.fc = nn.Sequential(nn.Linear(7*7*2048, 1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(1024, 256),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(256, 1),\n",
        "                            nn.Sigmoid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e90df19",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.382012Z",
          "iopub.status.busy": "2021-12-11T18:03:22.381191Z",
          "iopub.status.idle": "2021-12-11T18:03:22.402092Z",
          "shell.execute_reply": "2021-12-11T18:03:22.401681Z",
          "shell.execute_reply.started": "2021-12-10T10:25:37.15045Z"
        },
        "papermill": {
          "duration": 0.042246,
          "end_time": "2021-12-11T18:03:22.402205",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.359959",
          "status": "completed"
        },
        "tags": [],
        "id": "4e90df19"
      },
      "outputs": [],
      "source": [
        "train_data = ClassiData(train_path, star_df.values, non_df.values)\n",
        "train_data = DataLoader(train_data, batch_size = batch_size)\n",
        "optimizer = torch.optim.Adam(backbone.parameters(), lr = 0.0001)\n",
        "criteria = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afea6f8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.446796Z",
          "iopub.status.busy": "2021-12-11T18:03:22.445912Z",
          "iopub.status.idle": "2021-12-11T18:03:22.447737Z",
          "shell.execute_reply": "2021-12-11T18:03:22.448177Z",
          "shell.execute_reply.started": "2021-12-10T10:25:40.665904Z"
        },
        "papermill": {
          "duration": 0.029976,
          "end_time": "2021-12-11T18:03:22.448308",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.418332",
          "status": "completed"
        },
        "tags": [],
        "id": "afea6f8b"
      },
      "outputs": [],
      "source": [
        "def train_model_classi(model, train_data, criteria, optimizer, epochs, val_data = None, device = device):\n",
        "    min_val_loss = 10\n",
        "    model_state = None\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        tr_loss = 0\n",
        "        val_loss = 0\n",
        "        train_step = 0\n",
        "        acc = 0\n",
        "        val_acc = 0\n",
        "        for images, targets in tqdm(train_data):\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            pred = model(images)\n",
        "            loss = criteria(pred, targets)\n",
        "            train_step += 1\n",
        "            if train_step <= np.ceil(int(len(train_data)*0.8) / batch_size):\n",
        "                acc += torch.sum(pred.detach().cpu() > 0.5).item()\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                tr_loss += loss.item()\n",
        "            else:\n",
        "                val_acc += torch.sum(pred.detach().cpu() > 0.5).item()\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        tr_loss /= (int(len(train_data)*0.8))\n",
        "        acc /= (int(len(train_data)*0.8))\n",
        "        val_loss /= (len(train_data) - int(len(train_data)*0.8))\n",
        "        val_acc /= (len(train_data) - int(len(train_data)*0.8))\n",
        "        torch.cuda.empty_cache()\n",
        "        if val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            model_state = deepcopy(model.state_dict())\n",
        "        print(f'epoch: {epoch} loss: {tr_loss} acc: {acc} ;;;; val_loss: {val_loss} val_acc: {val_acc}')\n",
        "    model.load_state_dict(model_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4cd6705",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.488304Z",
          "iopub.status.busy": "2021-12-11T18:03:22.486647Z",
          "iopub.status.idle": "2021-12-11T18:03:22.488950Z",
          "shell.execute_reply": "2021-12-11T18:03:22.489365Z",
          "shell.execute_reply.started": "2021-12-10T10:25:42.047134Z"
        },
        "papermill": {
          "duration": 0.023931,
          "end_time": "2021-12-11T18:03:22.489538",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.465607",
          "status": "completed"
        },
        "tags": [],
        "id": "c4cd6705"
      },
      "outputs": [],
      "source": [
        "train_model_classi(backbone, train_data, criteria, optimizer, 5)\n",
        "torch.cuda.empty_cache()\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we implement the dataset for object detection. this dataset returns the images and their respective target dictionary. target dictionaries consist of target bounding boxes, areas and labels."
      ],
      "metadata": {
        "id": "2ehC1RFDVdX1"
      },
      "id": "2ehC1RFDVdX1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee465937",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.535155Z",
          "iopub.status.busy": "2021-12-11T18:03:22.530314Z",
          "iopub.status.idle": "2021-12-11T18:03:22.537751Z",
          "shell.execute_reply": "2021-12-11T18:03:22.538133Z",
          "shell.execute_reply.started": "2021-12-10T10:26:10.781483Z"
        },
        "papermill": {
          "duration": 0.031966,
          "end_time": "2021-12-11T18:03:22.538287",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.506321",
          "status": "completed"
        },
        "tags": [],
        "id": "ee465937"
      },
      "outputs": [],
      "source": [
        "class StarfishData(Dataset):\n",
        "    def __init__(self, train_path, df):\n",
        "        np.random.shuffle(df)\n",
        "        self.ids = df[:, 0]\n",
        "        self.frames = df[:, 1]\n",
        "        self.annotations = df[:, -1]\n",
        "        self.path = train_path\n",
        "        self.transforms = T.Compose([T.ToPILImage(), T.ToTensor()])\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        im_path = f'{self.path}video_{self.ids[idx]}/{self.frames[idx]}.jpg'\n",
        "        annot = eval(self.annotations[idx])\n",
        "        image = io.imread(im_path)\n",
        "        boxes = [[x['x'], x['y'], x['x'] + x['width'], x['y'] + x['height']] for x in annot]\n",
        "        areas = [x['width'] * x['height'] for x in annot]\n",
        "        is_crowd = [0] * len(areas)\n",
        "        labels = [1] * len(areas)\n",
        "        image = torch.from_numpy(image)\n",
        "        boxes = torch.as_tensor(boxes).type(torch.float32)\n",
        "        areas = torch.as_tensor(areas).type(torch.float32)\n",
        "        is_crowd = torch.as_tensor(is_crowd).type(torch.int64)\n",
        "        labels = torch.as_tensor(labels).type(torch.int64)\n",
        "        image = image.permute((2, 0, 1))\n",
        "        image = self.transforms(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = image.flip(-1)\n",
        "            boxes[:, [1, 3]] = image.size()[-1] - boxes[:, [3, 1]]\n",
        "        target = {}\n",
        "        target['boxes'] = boxes\n",
        "        target['area'] = areas\n",
        "        target['iscrowd'] = is_crowd\n",
        "        target['labels'] = labels\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354a9d20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.578353Z",
          "iopub.status.busy": "2021-12-11T18:03:22.577633Z",
          "iopub.status.idle": "2021-12-11T18:03:22.580732Z",
          "shell.execute_reply": "2021-12-11T18:03:22.580203Z",
          "shell.execute_reply.started": "2021-12-10T10:26:11.937129Z"
        },
        "papermill": {
          "duration": 0.026125,
          "end_time": "2021-12-11T18:03:22.580856",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.554731",
          "status": "completed"
        },
        "tags": [],
        "id": "354a9d20"
      },
      "outputs": [],
      "source": [
        "files = star_df.values\n",
        "val_ind = np.random.choice(len(files), len(files) // 5, replace = False)\n",
        "train_ind = np.delete(np.arange(len(files)), val_ind)\n",
        "train_files = files[train_ind]\n",
        "val_files = files[val_ind]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dcf6b92",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.628517Z",
          "iopub.status.busy": "2021-12-11T18:03:22.627650Z",
          "iopub.status.idle": "2021-12-11T18:03:22.629783Z",
          "shell.execute_reply": "2021-12-11T18:03:22.630227Z",
          "shell.execute_reply.started": "2021-12-10T10:26:13.626931Z"
        },
        "papermill": {
          "duration": 0.032686,
          "end_time": "2021-12-11T18:03:22.630373",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.597687",
          "status": "completed"
        },
        "tags": [],
        "id": "1dcf6b92"
      },
      "outputs": [],
      "source": [
        "train_data = StarfishData(train_path, np.concatenate((train_files, val_files), axis = 0))\n",
        "train_data = DataLoader(train_data, batch_size = batch_size, collate_fn = lambda x:tuple(zip(*x)))\n",
        "val_data = StarfishData(train_path, val_files)\n",
        "val_data = DataLoader(val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we read load the pretrained weights for the backbone."
      ],
      "metadata": {
        "id": "6qQaKmUIWqbj"
      },
      "id": "6qQaKmUIWqbj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccdc1b42",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.670390Z",
          "iopub.status.busy": "2021-12-11T18:03:22.668684Z",
          "iopub.status.idle": "2021-12-11T18:03:22.671085Z",
          "shell.execute_reply": "2021-12-11T18:03:22.671677Z",
          "shell.execute_reply.started": "2021-12-05T19:57:40.362222Z"
        },
        "papermill": {
          "duration": 0.024218,
          "end_time": "2021-12-11T18:03:22.671845",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.647627",
          "status": "completed"
        },
        "tags": [],
        "id": "ccdc1b42"
      },
      "outputs": [],
      "source": [
        "# vgg = torch.load('../input/vgg19/vgg19.pth')\n",
        "# backbone = torchvision.models.vgg19()\n",
        "# backbone.load_state_dict(vgg)\n",
        "# backbone = backbone.features\n",
        "# backbone.out_channels = 512\n",
        "# anchor_generator = AnchorGenerator(sizes = ((64,128,256,512),) , aspect_ratios = ((0.5 , 1 , 2),))\n",
        "# roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names = ['0'] , output_size = 7 , sampling_ratio = 2)\n",
        "# model = FasterRCNN(backbone , rpn_anchor_generator = anchor_generator , box_roi_pool = roi_pooler , num_classes = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbb4576",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:22.712958Z",
          "iopub.status.busy": "2021-12-11T18:03:22.711833Z",
          "iopub.status.idle": "2021-12-11T18:03:23.305538Z",
          "shell.execute_reply": "2021-12-11T18:03:23.305949Z",
          "shell.execute_reply.started": "2021-12-10T10:26:20.038699Z"
        },
        "papermill": {
          "duration": 0.61685,
          "end_time": "2021-12-11T18:03:23.306088",
          "exception": false,
          "start_time": "2021-12-11T18:03:22.689238",
          "status": "completed"
        },
        "tags": [],
        "id": "ccbb4576",
        "outputId": "3d4acb17-4aa7-4c46-be31-12ff809b1af6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet = torch.load('../input/resnet50/resnet50.pth')\n",
        "resnet = backbone.state_dict()\n",
        "model = fasterrcnn_resnet50_fpn(pretrained_backbone = False, num_classes = 2)\n",
        "# model.transform = torchvision.models.detection.transform.GeneralizedRCNNTransform(min_size = 100, max_size = 1300, fixed_size = (360, 640), image_mean = [0.485, 0.456, 0.406],image_std = [0.229, 0.224, 0.225])\n",
        "state = model.backbone.body.state_dict()\n",
        "for k in state.keys():\n",
        "    if k in resnet.keys():\n",
        "        state[k] = resnet[k]\n",
        "model.backbone.body.load_state_dict(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# finally it is time to train the model. we read images and targets from dataset and we calcuate the loss then we sum up all the losses and we back propagate and train the weights."
      ],
      "metadata": {
        "id": "EbbHK2dBXIG4"
      },
      "id": "EbbHK2dBXIG4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3deedd56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:23.353688Z",
          "iopub.status.busy": "2021-12-11T18:03:23.352373Z",
          "iopub.status.idle": "2021-12-11T18:03:23.355010Z",
          "shell.execute_reply": "2021-12-11T18:03:23.354608Z",
          "shell.execute_reply.started": "2021-12-10T10:26:26.891292Z"
        },
        "papermill": {
          "duration": 0.032044,
          "end_time": "2021-12-11T18:03:23.355116",
          "exception": false,
          "start_time": "2021-12-11T18:03:23.323072",
          "status": "completed"
        },
        "tags": [],
        "id": "3deedd56"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, optimizer, epochs, val_data = None, device = device):\n",
        "    min_val_loss = 10\n",
        "    model_state = None\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        keys = None\n",
        "        tr_loss = None\n",
        "        val_loss = None\n",
        "        train_step = 0\n",
        "        for images, targets in tqdm(train_data):\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k:v.to(device) for k , v in t.items()} for t in targets]\n",
        "            loss_dict = model(images , targets)\n",
        "            train_step += 1\n",
        "            if train_step <= np.ceil(len(train_ind) / batch_size):\n",
        "                loss = sum([x for x in loss_dict.values()])\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                tr_loss = torch.stack(list(loss_dict.values())).detach().cpu() if tr_loss is None else tr_loss + torch.stack(list(loss_dict.values())).detach().cpu()\n",
        "            else:\n",
        "                val_loss = torch.stack(list(loss_dict.values())).detach().cpu() if val_loss is None else val_loss + torch.stack(list(loss_dict.values())).detach().cpu()\n",
        "        \n",
        "        keys = list(loss_dict.keys())\n",
        "        tr_loss /= len(train_ind)\n",
        "        train_str = [f'{keys[i]}:{tr_loss[i].item()}' for i in range(len(keys))]\n",
        "        train_str = str.join('||' , train_str)\n",
        "        val_loss /= len(val_ind)\n",
        "        val_str = [f'{keys[i]}:{val_loss[i].item()}' for i in range(len(keys))]\n",
        "        val_str = str.join('||' , val_str)\n",
        "        torch.cuda.empty_cache()\n",
        "        if torch.sum(val_loss) < min_val_loss:\n",
        "            min_val_loss = torch.sum(val_loss)\n",
        "            model_state = deepcopy(model.state_dict())\n",
        "        print(f'{train_str};;;;{val_str}')\n",
        "    model.load_state_dict(model_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d994ba9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:23.431214Z",
          "iopub.status.busy": "2021-12-11T18:03:23.430443Z",
          "iopub.status.idle": "2021-12-11T18:03:23.432062Z",
          "shell.execute_reply": "2021-12-11T18:03:23.432875Z",
          "shell.execute_reply.started": "2021-12-10T10:26:30.531299Z"
        },
        "papermill": {
          "duration": 0.022709,
          "end_time": "2021-12-11T18:03:23.432997",
          "exception": false,
          "start_time": "2021-12-11T18:03:23.410288",
          "status": "completed"
        },
        "tags": [],
        "id": "9d994ba9"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3137df9e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T18:03:23.471263Z",
          "iopub.status.busy": "2021-12-11T18:03:23.470711Z",
          "iopub.status.idle": "2021-12-11T23:52:40.209317Z",
          "shell.execute_reply": "2021-12-11T23:52:40.209789Z",
          "shell.execute_reply.started": "2021-12-10T10:26:38.708467Z"
        },
        "papermill": {
          "duration": 20956.760942,
          "end_time": "2021-12-11T23:52:40.209963",
          "exception": false,
          "start_time": "2021-12-11T18:03:23.449021",
          "status": "completed"
        },
        "tags": [],
        "id": "3137df9e",
        "outputId": "62690b61-c4c2-4f75-8f69-4c7c5ff006f4",
        "colab": {
          "referenced_widgets": [
            "2ae68cb879994c7f838f6ef2acb9ccd9",
            "de910b62a0534647abbfc654e5b65bbb",
            "687511dfa82a4affa13c1c554732a821",
            "2d21624344334986be38ea3fe313b1e3",
            "4e48a31c5cfa49c4bd201af7a77fb13a",
            "2c6b4702838e4f90aa313ea58cb40ba1",
            "b803a363059749dbaa022a408cc45cfe",
            "696caed3d52c4bd78af0569022957dec",
            "81aba75598584ebe93082b4879ee856b",
            "639c04cb40d84b9db157e4bc6ff61cdf",
            "3b19680350bd4017bafca348b4441b0f",
            "c8e3979c818342ff9676979781a95ab6",
            "ca9df43f21d14f988ec46fd14e5c5b29",
            "4dc9581414534c288e60fb23e488c9fa",
            "f218ca1587a645959b48e61af7e94907",
            "0b6e4c46ea9948169ddd9abd4475b432",
            "2d1951c6945140d0a6c3dcc692f5e11b",
            "38a73201cdc946aea399efebfdf3e607",
            "bc68c81ba84b49939622a8cfa8fbbbc1",
            "d942c0296bb048ada1523352e378935a"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ae68cb879994c7f838f6ef2acb9ccd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.0926336869597435||loss_box_reg:0.01926822029054165||loss_objectness:0.5660269856452942||loss_rpn_box_reg:4.120506286621094;;;;loss_classifier:0.027312489226460457||loss_box_reg:0.006774798035621643||loss_objectness:0.5218324661254883||loss_rpn_box_reg:3.6710381507873535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de910b62a0534647abbfc654e5b65bbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03353343531489372||loss_box_reg:0.014418660663068295||loss_objectness:0.5505380034446716||loss_rpn_box_reg:3.6624109745025635;;;;loss_classifier:0.05336063355207443||loss_box_reg:0.012831361964344978||loss_objectness:0.5959644913673401||loss_rpn_box_reg:3.7681069374084473\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "687511dfa82a4affa13c1c554732a821",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03306502476334572||loss_box_reg:0.01581144891679287||loss_objectness:0.5388669371604919||loss_rpn_box_reg:3.0779714584350586;;;;loss_classifier:0.03641708567738533||loss_box_reg:0.022692520171403885||loss_objectness:0.510316789150238||loss_rpn_box_reg:2.4562265872955322\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d21624344334986be38ea3fe313b1e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03716249763965607||loss_box_reg:0.021008087322115898||loss_objectness:0.5227206349372864||loss_rpn_box_reg:2.716264247894287;;;;loss_classifier:0.032086439430713654||loss_box_reg:0.023462621495127678||loss_objectness:0.49201616644859314||loss_rpn_box_reg:2.4563796520233154\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e48a31c5cfa49c4bd201af7a77fb13a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03503391146659851||loss_box_reg:0.022677088156342506||loss_objectness:0.5097997784614563||loss_rpn_box_reg:2.6003096103668213;;;;loss_classifier:0.035743121057748795||loss_box_reg:0.02410336397588253||loss_objectness:0.5194811820983887||loss_rpn_box_reg:2.711249828338623\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6b4702838e4f90aa313ea58cb40ba1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.038966622203588486||loss_box_reg:0.02608516439795494||loss_objectness:0.5212851762771606||loss_rpn_box_reg:2.5547213554382324;;;;loss_classifier:0.03614703193306923||loss_box_reg:0.029005736112594604||loss_objectness:0.5187128782272339||loss_rpn_box_reg:2.583094596862793\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b803a363059749dbaa022a408cc45cfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03587023541331291||loss_box_reg:0.029167892411351204||loss_objectness:0.5025084018707275||loss_rpn_box_reg:2.3822107315063477;;;;loss_classifier:0.033442284911870956||loss_box_reg:0.029568595811724663||loss_objectness:0.5175173878669739||loss_rpn_box_reg:2.6116812229156494\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "696caed3d52c4bd78af0569022957dec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.03839766979217529||loss_box_reg:0.0338815301656723||loss_objectness:0.49472498893737793||loss_rpn_box_reg:2.302732229232788;;;;loss_classifier:0.03684091940522194||loss_box_reg:0.036520205438137054||loss_objectness:0.4913114011287689||loss_rpn_box_reg:2.3034512996673584\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81aba75598584ebe93082b4879ee856b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.04054247960448265||loss_box_reg:0.03499697893857956||loss_objectness:0.5152475833892822||loss_rpn_box_reg:2.473705530166626;;;;loss_classifier:0.03264222294092178||loss_box_reg:0.031113430857658386||loss_objectness:0.5082297921180725||loss_rpn_box_reg:2.6827752590179443\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "639c04cb40d84b9db157e4bc6ff61cdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.04442007839679718||loss_box_reg:0.03866293653845787||loss_objectness:0.5009245872497559||loss_rpn_box_reg:2.366549015045166;;;;loss_classifier:0.031394876539707184||loss_box_reg:0.028515568003058434||loss_objectness:0.523177444934845||loss_rpn_box_reg:2.6895787715911865\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b19680350bd4017bafca348b4441b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.04819599539041519||loss_box_reg:0.04195871949195862||loss_objectness:0.4912000298500061||loss_rpn_box_reg:2.2549612522125244;;;;loss_classifier:0.03462108224630356||loss_box_reg:0.035490937530994415||loss_objectness:0.4714031219482422||loss_rpn_box_reg:2.127817392349243\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8e3979c818342ff9676979781a95ab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.05084967240691185||loss_box_reg:0.04539933428168297||loss_objectness:0.49549755454063416||loss_rpn_box_reg:2.2549617290496826;;;;loss_classifier:0.042075030505657196||loss_box_reg:0.04318547621369362||loss_objectness:0.48796743154525757||loss_rpn_box_reg:2.411322593688965\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca9df43f21d14f988ec46fd14e5c5b29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.054211266338825226||loss_box_reg:0.05147261172533035||loss_objectness:0.4708094298839569||loss_rpn_box_reg:2.1552798748016357;;;;loss_classifier:0.03651880472898483||loss_box_reg:0.04394332692027092||loss_objectness:0.5319865345954895||loss_rpn_box_reg:2.5058372020721436\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dc9581414534c288e60fb23e488c9fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.058042991906404495||loss_box_reg:0.05474770441651344||loss_objectness:0.47629666328430176||loss_rpn_box_reg:2.150578022003174;;;;loss_classifier:0.04464937746524811||loss_box_reg:0.05095789581537247||loss_objectness:0.4899756610393524||loss_rpn_box_reg:2.1604809761047363\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f218ca1587a645959b48e61af7e94907",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.06055605039000511||loss_box_reg:0.050765857100486755||loss_objectness:0.5314667224884033||loss_rpn_box_reg:2.3206276893615723;;;;loss_classifier:0.06890127062797546||loss_box_reg:0.06470700353384018||loss_objectness:0.4707297086715698||loss_rpn_box_reg:2.1211154460906982\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b6e4c46ea9948169ddd9abd4475b432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.06550464034080505||loss_box_reg:0.062001243233680725||loss_objectness:0.4759283661842346||loss_rpn_box_reg:2.1334495544433594;;;;loss_classifier:0.04507775604724884||loss_box_reg:0.057751696556806564||loss_objectness:0.44580450654029846||loss_rpn_box_reg:1.9554444551467896\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d1951c6945140d0a6c3dcc692f5e11b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.061220645904541016||loss_box_reg:0.05205690860748291||loss_objectness:0.48818740248680115||loss_rpn_box_reg:2.2653932571411133;;;;loss_classifier:0.05229996517300606||loss_box_reg:0.0417497381567955||loss_objectness:0.48570695519447327||loss_rpn_box_reg:2.434040069580078\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38a73201cdc946aea399efebfdf3e607",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.05689128860831261||loss_box_reg:0.056882020086050034||loss_objectness:0.4784905016422272||loss_rpn_box_reg:2.1741628646850586;;;;loss_classifier:0.09095174819231033||loss_box_reg:0.07436792552471161||loss_objectness:0.44322827458381653||loss_rpn_box_reg:1.9288464784622192\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc68c81ba84b49939622a8cfa8fbbbc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.05351675674319267||loss_box_reg:0.055700644850730896||loss_objectness:0.4779527485370636||loss_rpn_box_reg:2.130586862564087;;;;loss_classifier:0.04211590439081192||loss_box_reg:0.05344346538186073||loss_objectness:0.44754552841186523||loss_rpn_box_reg:1.994939923286438\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d942c0296bb048ada1523352e378935a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4919 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_classifier:0.06297570466995239||loss_box_reg:0.059919629245996475||loss_objectness:0.4694163203239441||loss_rpn_box_reg:2.147547960281372;;;;loss_classifier:0.05837774649262428||loss_box_reg:0.05128508433699608||loss_objectness:0.43657904863357544||loss_rpn_box_reg:2.0517847537994385\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_data, optimizer, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in the end model is ready to be tested and in the following cells you can see how."
      ],
      "metadata": {
        "id": "olaaasGYX-eb"
      },
      "id": "olaaasGYX-eb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504445a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T23:52:40.275825Z",
          "iopub.status.busy": "2021-12-11T23:52:40.275136Z",
          "iopub.status.idle": "2021-12-11T23:52:40.277766Z",
          "shell.execute_reply": "2021-12-11T23:52:40.277295Z",
          "shell.execute_reply.started": "2021-12-05T21:24:34.466759Z"
        },
        "papermill": {
          "duration": 0.038329,
          "end_time": "2021-12-11T23:52:40.277875",
          "exception": false,
          "start_time": "2021-12-11T23:52:40.239546",
          "status": "completed"
        },
        "tags": [],
        "id": "504445a2"
      },
      "outputs": [],
      "source": [
        "class StarfishTest(Dataset):\n",
        "    def __init__(self, train_path, df):\n",
        "        self.path = train_path\n",
        "        self.ids = df[:, 0]\n",
        "        self.frames = df[:, 1]\n",
        "        self.transforms = T.Compose([T.ToPILImage(), T.ToTensor()])\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        im_path = f'{self.path}video_{self.ids[idx]}/{self.frames[idx]}.jpg'\n",
        "        image = io.imread(im_path)\n",
        "        image = torch.from_numpy(image)\n",
        "        image = image.permute((2, 0, 1))\n",
        "        image = self.transforms(image)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77af380",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T23:52:40.340075Z",
          "iopub.status.busy": "2021-12-11T23:52:40.339357Z",
          "iopub.status.idle": "2021-12-11T23:52:40.341519Z",
          "shell.execute_reply": "2021-12-11T23:52:40.341901Z"
        },
        "papermill": {
          "duration": 0.035359,
          "end_time": "2021-12-11T23:52:40.342017",
          "exception": false,
          "start_time": "2021-12-11T23:52:40.306658",
          "status": "completed"
        },
        "tags": [],
        "id": "a77af380"
      },
      "outputs": [],
      "source": [
        "test_data = StarfishTest(train_path, test_df.values)\n",
        "# test_data = DataLoader(test_data, collate_fn = lambda x:tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b0fca4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T23:52:40.406064Z",
          "iopub.status.busy": "2021-12-11T23:52:40.405171Z",
          "iopub.status.idle": "2021-12-11T23:52:40.407726Z",
          "shell.execute_reply": "2021-12-11T23:52:40.407301Z",
          "shell.execute_reply.started": "2021-12-03T09:07:09.426501Z"
        },
        "papermill": {
          "duration": 0.036276,
          "end_time": "2021-12-11T23:52:40.407828",
          "exception": false,
          "start_time": "2021-12-11T23:52:40.371552",
          "status": "completed"
        },
        "tags": [],
        "id": "83b0fca4"
      },
      "outputs": [],
      "source": [
        "def get_pred(pred):\n",
        "    p = [f'{s} {b[0]} {b[1]} {b[2] - b[0]} {b[3] - b[1]}' for s,b,l in zip(pred['scores'],pred['boxes'],pred['labels']) if s > 0.5 and l == 1]\n",
        "    return ' '.join(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06da396",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-11T23:52:40.470373Z",
          "iopub.status.busy": "2021-12-11T23:52:40.469586Z",
          "iopub.status.idle": "2021-12-11T23:52:41.104108Z",
          "shell.execute_reply": "2021-12-11T23:52:41.103626Z",
          "shell.execute_reply.started": "2021-12-03T09:07:26.442925Z"
        },
        "papermill": {
          "duration": 0.667198,
          "end_time": "2021-12-11T23:52:41.104236",
          "exception": false,
          "start_time": "2021-12-11T23:52:40.437038",
          "status": "completed"
        },
        "tags": [],
        "id": "f06da396"
      },
      "outputs": [],
      "source": [
        "import greatbarrierreef\n",
        "model.eval()\n",
        "transform = T.Compose([T.ToPILImage(), T.ToTensor()])\n",
        "env = greatbarrierreef.make_env()\n",
        "iter_test = env.iter_test()\n",
        "for (pixel_array, sample_prediction_df) in iter_test:\n",
        "    im = transform(torch.from_numpy(pixel_array).permute((2, 0, 1))).to(device)\n",
        "    sample_prediction_df['annotations'] = get_pred(model([im])[0])\n",
        "    env.predict(sample_prediction_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 20974.698165,
      "end_time": "2021-12-11T23:52:43.664040",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-12-11T18:03:08.965875",
      "version": "2.3.3"
    },
    "colab": {
      "name": "Copy of starfish-detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}